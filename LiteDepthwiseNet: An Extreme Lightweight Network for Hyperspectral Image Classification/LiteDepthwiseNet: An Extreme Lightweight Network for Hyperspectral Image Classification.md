# 摘要 # 
- 基于三维深度卷积，LiteDepthwiseNet可以将标准卷积分解为深度卷积和点态卷积，以最小的参数获得较高的分类性能。
- 去除了原始三维深度卷积中的ReLU层和Batch Normalization layer，显著改善了模型在小数据集上的过拟合现象。
- 采用focal loss作为损失函数，提高了模型对困难样本和不平衡数据的关注度，其训练性能明显优于交叉熵损失和平衡交叉熵损失
# INTRODUCTION #
- 上述DL模型通常需要大量的训练样本和网络参数，而且计算量也较高
- HSI在分类中的标记成本和可用性都非常有限。此外，这些标记数据的类别分布是不均匀的。
- 轻量级的神经网络LiteDenseNet被提出用于HSI分类。与传统的3D-CNN结构不同，LiteDenseNet采用了三维双向密集结构，采用了群卷积，大大减少了参数的数目和计算成本。然而，群卷积切断了不同通道的连接，并可能导致精度的损失。
- 一个非常轻量级的HSI分类任务网络LiteDepthwiseNet优点：
- 1、用三维深度卷积代替群卷积。三维深卷积中的点态卷积可以连接所有的高光谱通道，相应的网络结构具有全通道接收场，更适合于HSI分类任务。基于这种新的网络结构，LiteDepthwiseNet只涉及很少的参数和触发器
- 2、引入焦点损失（FL）代替主流交叉熵损失（CEL）作为损失函数。它增加了对小样本和难分类样本的关注，有助于提高模型的最终性能。
- 3、去除了原始三维深卷积网络的中间激活层和归一化层，增强了模型的线性度，减少了HSI训练样本较少时的过拟合现象。
# RELATED WORK #
## A. 2D 深度可分离卷积 ##
- Fig. 1 标准卷积
- Fig. 2深度可分离卷积，标准卷积分解为深度卷积和点态卷积两个过程，在一定条件下可以显著降低二维卷积的计算量和参数个数。
## B. 交叉熵损失函数 ##
- （1）标准交叉熵损失函数 p表示类别中样本的预测概率，y表示样本是否正确分类，y是一个等于0或1的指示变量。可以观察到，当y为1时，p越接近1，损失越小；如果y为0，p越接近0，则损失越小，这符合优化的方向。
- （2）我们引入分段函数F，简化表达式
- （3）交叉熵损失函数另一种形式
- （4）
