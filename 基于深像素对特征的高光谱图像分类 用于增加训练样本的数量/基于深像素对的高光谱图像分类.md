# 基于深像素对的高光谱图像分类 #

## 摘要 ##
训练样本足够大的情况下，CNN可以提供很好的高光谱图像分类性能。论文提出了一种新的像素对方法来增加训练样本数量，确保发挥CNN的优势。对于一个测试像素，由训练好的CNN对中心像素和每个周围像素组成的像素对进行分类，然后通过投票策略确定最终的标签。

## 引言 ##
- 本文提出了一种新的基于深度CNN学习的像素对特征的分类框架。
- 在训练过程中，首先选择任意两个样本配对，来自同一类的样本标记不变，而来自不同类的样本标记为0，将新标签配对的样本输入到CNN中。
- 在测试过程中，通过训练好的CNN对于每个测试像素及其周围构造的相邻像素对进行分类，然后根据联合分类结果通过投票策略确定最终的标签。

## II提出的分类框架 ##
- 图1 基于深度PPFs分类框架流程图
- 利用可用的训练样本构建像素对模型，CNN架构来学习PPFs，根据联合分类结果通过投票策略来确定测试样本的标签。
　
### A 训练样本的像素对模型 ###
- 在像素对模型中，两个训练样本选自数据集X，若来自同类则sij的标签不变，若不同类则sij标签变为0 
- 图2说明了构建新数据集的过程，新的带标签的数据集有C+1类，第（C＋１）类样本可选自任意两个不同得类。对于第l类，像素对得数量可以通过所有排列计算。对于（sij）=0,由于样本可以选自任意两个类，所有像素对的数量比较多。为了保证数据平衡，只选择像素对近似相等的

### B 利用CNN特征提取 ###
- 图3用CNN提取PPFs（获得输入样本）
- CNN前馈神经网络（卷积层、最大池化层、全连接层），有10个卷积层，每层后都有一个RELU层，3个最大池化层。
- C1 输入数据2×200×1——10个1×9×1的核——2 × 192 × 10张量
- C2 输入2 × 192 × 10 ——10个2×1×10核——1×192×10 张量
- C3 输入1×192×10 张量 —— 10个1 × 3 × 10核——1×192×10 张量——1 × 3最大池化层降光谱维度
- C4 输入1 × 64 × 10张量——20个1 × 3 × 10卷积核——1×62×20 
- 三个最大池化层降低光谱维度
- C8 输入 1 × 13 × 40 ——80个 1 × 13 × 40 核—— 1 × 1× 80 张量
- FC1和FC2 ——卷积层

### 带有投票策略的联合分类 ###
- 图4基于带有投票策略的联合分类的PPFs
-相邻像素属于同一类（高概率）————在测试过程中构建带有投票策略的联合分类。对于一个测试像素，与周围的样本构造像素对，然后输入经过训练的CNN。神经网络的输出是一个C+1维张量，每一行表示每对属于这些类的概率分数(考虑标签为0到C的类，而标签为0的类C+1将不再考虑)。
- 中心像素T，配成8对，输入到CNN，输出是带有分数的8 × (C + 1)的矩阵，去掉第一列，得到8 ×C矩阵——softmax layer— 8×1向量（所有对的标签），中心像素的标签根据多数投票策略决定
- 图5 3×3 窗口联合分类例子
 
## 实验结果 ##
- 程序利用Python和TensorFlow库
- 表1到表3数据集印度松树，萨利纳斯和帕维亚大学，提取200个作为训练集
- 表4 帕维亚大学 特征数量和窗口大小不同的分类性能
- 表5有无全连接层的分类精度
- 表6-8三个数据集用不同算法的每类分类精度和OA值
- TABLE IX 采用标准化的McNemar s检验[30]来证明表IX中所列的提议的CNN-PPF在提高准确度方面的统计意义。McNemar s检验Z值大于1.96和2.58，说明在95%置信水平和99%置信水平下，两个结果有统计学差异。符号Z表示分类器1是否优于分类器2
-图6-图8 三个数据集的分类图
- 图9 展示了训练样本数目不同时的分类性能。
- TABLE X 总结了使用原始CNN[23]和提议的CNN- ppf进行训练和测试的计算复杂度。在训练过程中，原因可以是卷积层和全连接层的数量小于卷积层;而且，前者(到网络的)输入数据的大小远小于后者(数值分析可以在II-B节中找到)。在测试过程中，由于基于像素对模型的联合分类计算量较大，CNN-PPF测试费时较多。
