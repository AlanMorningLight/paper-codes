# 具有自动图学习的多尺度图卷积网络用于高光谱图像分类 #
## 摘要 ##
- 缺点：1、目前基于GCN的方法将图形构建和图像分类视为两个独立的任务，这往往导致性能不理想。2、主要侧重于对图节点之间局部成对重要性的建模，而缺乏捕捉HSI全局上下文信息的能力。
- MGCN-AGL:它可以在局部和全局两级自动学习图形信息。1、通过使用注意机制来表征空间相邻区域之间的重要性，可以自适应地将最相关的信息合并到决策中，从而对空间上下文进行编码，形成局部层次的图形信息。2、利用多路径进行局部图卷积，以充分利用HSI不同空间背景的优点，并提升所产生表示的表现力。3、为了重建全局上下文关系，我们的MGCN-AGL基于在局部产生的表达对图像区域之间的长程依赖进行编码。然后沿着连接遥远区域的重构图边缘进行推理。4、对多尺度信息进行自适应融合，生成网络输出。这样，图学习和图像分类就可以集成到一个统一的框架中，并且可以互相促进。
## 引言 ##
- CNN缺点：1、CNN无法感知不同目标区域之间的几何变化，因为它的卷积核被设计成只在规则平方区域中执行。2、卷积核的权值在卷积所有HSI块时保持不变，这必然会导致类边界信息的大量丢失，从而降低特征的代表性。因此，CNN中使用的形状和权重固定的卷积核不能很好地适应HSI中的不规则结构。
- GCN优点：与CNN不同，GCN可以对图结构数据进行操作，包括社会网络数据和基于图的分子表示，并且能够跨图节点传递、转换和聚合特征信息。这样，GCN可以应用于非欧几里德数据，从而灵活地保留了不同区域的类边界。
- 早期GCN缺点：1、HSI中本来就没有图形信息，直接获取图形信息的方法是根据成对欧几里德距离事先人工构造图。然而，欧几里德距离对于揭示图数据之间的关系可能不是最佳的，因此构造的图可能是有噪声的，或者具有与标签一致性不符的边，这将最终削弱所生成表示的表达能力。2、上述方法主要集中在对局部区域之间的成对重要性进行编码，而忽略了长程相关性，因此未能考虑全局上下文。
- 提出了一种多级图卷积网络自动图学习（MGCN-AGL）方法，在统一的框架内自动学习图节点之间的局部空间重要性和全局上下文信息。为了精确地利用局部区域之间的关系，该模型在训练过程中自适应地描述具有可学习尺度系数的成对重要性。该网络可以自动学习局部空间层次上的图形信息，减少不精确的预计算图形的负面影响。因此，该模型能够集中于每个区域最相关的空间信息来进行决策。此外，通过不同空间层次的图形卷积，可以在多个空间层次上综合捕捉上下文信息。结果表明，该方法能够更好地表达具有不同物体外观的区域，从而提高特征表示的表达能力。
## RELATED WORK ##
### A. Deep-Learning-based Hyperspectral Image Classification
- 基于CNN的分类方法在HSI分类中取得了很好的效果，但它们只是将固定的卷积核应用于不同的图像区域，在复杂的情况下不可避免地会造成信息丢失，从而导致分类结果不理想。
### B. Graph Convolutional Network 
## PROPOSED METHOD ##
- 图1。算法框架。（a） 是输入的高光谱数据。（b） 表示通过over-segmenting分割原始HSI获得的区域。（c） 表示在多个空间层次上的图卷积，利用注意机制自动学习区域间的成对重要性。这里，ReLU[45]被用作激活函数。（d） 显示了全局的图卷积，其中拓扑图信息根据在局部级生成的表示自动重构。在（e）中，分类结果是通过对多层次输出的自适应积分得到的。
### A. Region-based Segmentation
- 采用了一种称为SLIC的分割技术将原始HSI分割成一组紧凑的均匀图像区域，每个区域由少量具有强烈光谱空间相关性的像素组成。具体地说，SLIC算法通过使用k-means算法迭代地增长局部簇来执行分割。分割完成后，将每个图像区域视为一个图节点，从而大大减少了图的节点数，从而加速了后续的图卷积。在这里，区域特征可以通过计算所涉及像素的平均光谱特征来获得。
### B. Automatic Graph Learning 
- 获取图的一种常用方法是预先计算图节点（即图像区域）之间的成对欧几里德距离。然而，HSI中不同类型噪声的存在会降低生成图的质量。同时，由于模型训练和图的构造是孤立的步骤，因此得到的图可能不适合后续的分类任务。为了改善这一问题，提出了从局部和全局两个层次自动地学习图形信息，并将其自然地集成到分类模型中。
- 为了对HSI的局部空间上下文进行建模，我们利用注意力机制自动捕捉图像区域之间的上下文关系，而不是使用预先计算的固定权重（如欧几里德距离）作为两两重要性的度量。作为初始步骤，将一个加权矩阵W参数化的共享线性变换应用于每个节点（即，区域）xi作为编码器，旨在产生具有足够表达能力的特征表示。
- (1)对编码的节点特征进行self-attention.注意力系数Cij揭示XI和XJ之间的两两重要性时，a是可学习的权重向量，||表示连接两个向量的操作。
- (2)用SoftMax函数对席的所有空间邻域进行关注系数CiJ的归一化.以便在不同节点之间进行比较。从属性值的角度看，归一化注意系数αij可以表示为一个单层前馈神经网络，该网络由一个具有LeakyReLU 非线性的权重向量a参数化。
- (3)完全展开后，注意机制可以表达为
- 图2。局部空间水平上的图形信息学习。两个节点中的每一个都充当另一个节点的空间邻居.图2说明如何学习两个节点之间的成对重要性。通过利用注意机制，我们提出的模型可以自动地从局部空间邻域中聚集重要的特征信息。因此，与文献[19]和[13]相比，该图学习模型对高光谱数据中包含的噪声不太敏感。
- 图3。在我们的方法中多层次空间信息的开发。HSI中经常存在着不同类型的地物，同一土地覆盖类别的地物区域甚至可能具有不同的大小和形状[9]。因此，上述的图学习模型只从单一的空间层面整合上下文信息，不足以取得令人满意的结果。为了解决这个问题，我们打算利用多个空间层次的优点。不同分支中使用的图包含不同的邻域尺度。Z（l）1和Z（l）2分别表示在分支1和分支2中从第l层（l＝1或2）生成的表示。绿色和橙色节点表示中心蓝色节点的空间邻居。
- (4)分支，b=1或2
- (5)分支，b=1或2
- (6)Zloc代表局部尺度得输出
- (7)利用学习的特征表示Zloc，可以得到重构图的邻接矩阵
- (8) 重构损失，用来提升图的区分能力。YG表示对应于标记实例的索引集合，Yi表示xi的类标签，1[yi=yj ]是指示函数
- (9)只保留重要度很强的图边，并去掉其他边，β设置称0.75
- (10)第l层全局尺度的卷积层输出
- (11)使用了两层图卷积层，全局尺度的输出
### C. Integration of Multi-Level Contextual Information
- (12)公式（6）修改为(12),为了解决计算局域级输出Zloc时，对多个空间层次上的表示进行同等处理，这不可避免地忽略了它们感知物体外观变化的不同能力这一缺陷。
- (13)权重矩阵参数化的线性变换
- （14）模型预测值，λloc和λglo用来学习不同尺度的上下文信息的重要性
- （15）除了优化式（8）的重建误差外，还采用交叉熵误差来惩罚网络输出与原始标记区域的标签之间的差异
- （16）整体损失函数，ζ是分配给交叉熵误差的系数，可以通过梯度下降来学习。在我们提出的方法中，所有的网络参数都是通过整批梯度下降来更新的。
- 算法1
## EXPERIMENTAL RESULTS
### A. Datasets
- Houston University（休斯敦大学）
- Indian Pines
- Salinas
### B. Experimental Settings 
- 随机选择30个标记像素进行网络训练。如果对应的类包含少于30个像素，将随机选择15个，剩下的部分留作测试。
- 表2 学习速率η、迭代次数T、隐藏单元数u以及邻域尺度s1和s2
- 使用了两种基于CNN的方法，即基于不同区域的深层CNN（DR-CNN）[9]和CNN像素对特征（CNN-PPF）[48]，以及两种基于GCN的方法，即光谱空间图卷积网络（S2GCN）[19]和多尺度动态图卷积网络（MDGCN）作为对比
### C. Classification Results
- 表三显示了在休斯顿大学数据集上用不同方法获得的定量分类结果，其中最高值在每行中用粗体标记。图4展示了休斯顿大学数据集上七种不同方法产生的分类结果的可视化比较
- 表四报告了不同方法在印度松数据集上的定量结果。图5显示了通过使用不同方法生成的结果
- 表五中，我们定量地评估了不同方法在Salinas数据集上的分类性能，图6视觉比较。
### D. Impact of the Number of Labeled Examples 
- 图7展示了我们提出的MGCN-AGL和基线方法在不同初始标记样本数下的分类性能。具体地说，我们将每个类标记样本数从5个变为30个，间隔为5个，并在三个数据集（即休斯顿大学、印度松和沙柳）上报告所有七种方法获得的OA。
### E. Parametric Sensitivity 
- 将s1固定为1，并将另一个参数s2从2调整到5。图8提供了用我们的方法获得的不同s2值的详细分类结果。观察图8所示的曲线，值得注意的是邻域大小的选择对于我们的MGCN-AGL实现令人满意的性能至关重要。
- 对于三个高光谱数据集，我们的方法采用的s2值如表II所示
### F. Ablation Study 
- 将未使用全局上下文信息的分类结果重新导入，并将简化后的模型表示为“MGCN-AGL-Loc”。每个类的标记像素数与第IV-C节中的上述实验相同。表VI-VIII分别展示了休斯顿大学、印度松和萨利纳斯数据集的比较结果。
