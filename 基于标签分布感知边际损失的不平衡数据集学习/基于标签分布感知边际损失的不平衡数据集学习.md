# 基于标签分布感知间隔损失的不平衡数据集训练
## 摘要 
- 当训练数据集存在严重的类不平衡时，深度学习算法的性能较差，但测试准则要求对较少出现的类进行良好的泛化。我们设计了两种新的方法来提高这种情况下的性能。
- 提出标签分布感知间隔（LDAM）损失，其受最小化一个基于间隔的泛化界启发。该损失代替了训练过程中的标准交叉熵目标，并可用于类不平衡的先验训练策略，如重加权或重采样。其次，我们提出了一个简单而有效的训练计划，将重新加权推迟到初始阶段之后，允许模型学习初始表示，同时避免与重新加权或重新采样相关的一些复杂情况。
## 引言
- 1、大规模的真实数据集通常时长尾分布的，深层神经网络在代表性较低的类上表现不佳，如果测试标准更加强调少数类别，这种现象尤其严重。
- 2、学习长尾数据集的两种常用方法：对随机梯度下降法的小批量中样本的损失重加权和样本重采样。两种方法都设计了一个更接近测试分布的训练损失，就可以在多数类和少数类之间实现更好的权衡。但是少类的信息很少，而模型很大，改进的方法会出现过拟合。
- 3、对少数类比多数类进行更强的正则化，可以改善少数类的泛化能力。实现这一思想需要一个依赖数据或者标签的正则化器，用于区分多数类和少数类。
- 4、本论文讨论的是依赖于数据的方法：训练样本的间隔。找到最大的间隔可以看作是正则化，因为标准泛化误差界依赖于所有样本最小间隔的倒数。基于对少数类泛化问题，本文研究每一类的最小间隔，获得每一类和均匀标签测试误差界，最小化这个界就可获得所有类间隔的最佳折衷。
- 图1说明了二分类问题。间隔ri表示的是第i类数据到决策边界的最小距离，带有均匀标签分布的测试误差是由式（）决定的。固定决策边界的方向，则r1+r2就固定，它们之间的权衡可以通过移动决策边界来优化。
- 5、受上述理论启发，设计了标签分布感知损失函数使得模型获得每一类间隔的最优权衡。提出的损失函数使少数类具有大的间隔来增大存在的软间隔损失。此外，还设计了一个延迟重平衡优化过程，使重加权与损失以更有效的方式结合。
- 总结：（1）设计了一个标签分布感知损失函数，使得少数类获得更大的间隔。（2）提出了一个简单的简单的延迟重平衡优化过程，使重加权更加的有效。
## 相关工作
- 有的学习不平衡数据集的算法可分为两类：重采样和重加权
- 重采样：有两种形式：对于少数类的过采样和多数类的欠采样。欠采样的缺点是丢弃了大部分的数据，在数据极端不平衡时是不可行的。过采样大多数情况下可行，但是对于少数类会导致过拟合，数据增强可以缓解过拟合。
- 重加权：计算敏感的重加权对不同类甚至不同样本进行重加权。本论文中尽可能使得少数类具有很高的间隔，因此我们不会收敛到最大间隔解。在实验中，采用Ｌ2正则化来获得最好的泛化性能。同时，延迟重加权要比开始训练时采用重加权和重采样更有效。
- 总结上述，通过采用正交于重加权的附加正则化来提高少数类的泛化，还提出了延迟重平衡优化方法来提高一般重加权方案的优化和泛化。
- 间隔损失：hinge loss 主要用来获得最大间隔分类器。本论文中主要是使得少数类获得更大的间隔。
- 域适应里的标签变化：学习不平衡数据集的问题也可以看做是转换学习或者域适应的标签转换问题。
- 元学习：元学习也被用于改善不平衡数据集的性能
## 主要的方法
### 理论动机
#### 问题设置及符号：
- （0）在平衡数据分布上的标准0-1测试误差 [X-输入；y-输出；Pj = P(x | y = j) -类条件分布；Pbal-平衡测试分布，首先均匀地抽取一个类，然后从pj中抽取数据；f-模型]
- （1）样本（x,y）的间隔 
- （2）表示的是类别j的训练间隔
#### 详细的泛化误差边界：
- （3）不平衡的测试误差[ F-假设类的簇； C（F）假设类F的复杂性度量]
- 如果训练分布和测试分布是相同的，则典型的泛化误差界C(F)/√ n,若测试分布和训练分布一样都是不平衡的，则有公式（3），与标签分布无关，只与所有样本的最小间隔和数据的总数有关。
#### 定理1：
- （4） 每一类泛化误差界-训练数据的随机性具有很高的概率，对于类j的误差是有界的。
- （5）平衡泛化误差界-平衡的是少数类与多数类的间隔
#### 类分布感知间隔权衡：
- 公式（4）表明若想提高少数类的泛化性能，需要增加它们的间隔rj，但是增加少数类的间隔将会破坏多数类的间隔。
- 对于K=2,目的是优化平衡泛化误差界（5）由于γ1和γ2是权重矩阵的复杂函数，因此很难获得最佳间隔。然而，我们可以计算出γ1和γ2之间的相对标度。假设γ1，γ2>0最小化上述方程，任何γ0 1=γ1−δ和γ0 2=γ2+δ（对于δ∈（−γ2，γ1））都可以通过具有移位偏差项的相同权重矩阵来实现。因此，要使γ1、γ2最优，它们应满足（7）
#### 快速率与慢速率及在间隔选择方面的应用
- 快速率与慢速率，以及对间隔选择的影响。定理1中的界限不一定是紧致的。标度为1/√n（或1/√ni，此处为不平衡类）的泛化界通常称为“慢速率”，标度为1/n的泛化界称为“快速率”。对于深度神经网络，当模型足够大时，有可能将其中一些边界提高到快速率。在这些情况下，我们可以得出间隔的最佳权衡为ni∞ni−1/3。
### 标签分布感知间隔（LDAM）损失
- 基于上述的两类，推及到多类，损失设（x，y）为样本，f为模型。使zj=f（x）j来表示j-th类模型的第j次输出。hinge loss的多类扩展（10）C是一个需要调整的超参数。根据经验，上述损失的非光滑性会给优化带来困难，根据交叉熵得hinge loss具有光滑松弛形式（12）
### 延迟重平衡优化方法
- 重加权和重采样是处理不平衡数据集两种比较成功的策略，因为它们可以有效的使不平衡的训练分布更接近均匀的测试分布。应用上述技术会有两种问题：（a）当模型是深层神经网络时，对少数类样本进行重采样会导致少数类的严重过拟合。（b）对少数类损失加权会导致优化的困难和不稳定。
- 我们从经验观察到，在学习率退火前，重加权和重采样都不如经验风险最小化（ERM）算法，产生的特征相比ERM更差。所以设计了延迟再平衡训练方法（算法1）。在学习率退火前，首先使用带有LDAM损失的常规 ERM进行训练，然后使用具有较小学习率的重新加权的LDAM损失。从经验上讲，第一阶段的训练可以为第二阶段的训练带来良好的初始化，并重新加权损失。由于损失是非凸的，并且第二阶段的学习率相对较小，所以第二阶段不会将权重改变太大。。
- 算法：具有LDAM损失的延迟再平衡优化算法
## 实验
- 四个人为创建的数据集，数据不平衡具有可控性。一个真实世界的大规模不平衡数据集。
- 基准。（1）经验风险最小化（ERM）损失：所有的样本具有相同的权重，使用标准的交叉熵损失。（2）重加权（RW）：我们用类的样本大小的倒数来重新加权每个样本，然后重新规范化，使小批量中的权重平均为1。（3） 重采样（RS）：每个样本的抽样概率与其类的逆样本大小成比例。（4） CB[10]：根据每类有效样本数的倒数，重新加权或重新取样，定义为（1−βni）/（1−β），而不是类频率的倒数。这种想法可以与重新加权或重新抽样相结合。（5） Focal：我们使用最近提出的Focal损失作为另一个基准。（6） SGD：在SGD中，我们指的是标准方法，其中学习率在某些步骤中以常数衰减；我们使用标准的学习速率衰减方法。
- 提出的算法和变换。（1） DRW和DRS：按照所提出的训练算法1，我们使用标准的ERM优化直到最后一个学习速率衰减，然后在第二阶段应用重加权或重采样进行优化。（2） LDAM：提出的标签分布感知间隔损失。我们提出的主要算法是LDAM-DRW。
### IMDB数据集实验结果
- 原始数据集包含均匀分布的正面和负面评论。人为去掉了90%的负面评价创建了一个不平衡的训练集。
### CIFAR实验结果
- CIFAR-10和CIFAR-100不平衡数据集。CIFAR-10和CIFAR-100的原始数据集分别包含50000个训练图像和10000个大小为32×32的验证图像，分别有10个和100个类。为了创建它们的不平衡数据集，减少了每个类的训练样本数，并保持验证集不变。为了确保我们的方法适用于各种设置，我们考虑了两种类型的不平衡：长尾不平衡和阶跃不平衡。表2两个数据集的top-1验证错误率
### iNaturalist 2018
- Invatalist物种分类和检测数据集是一个真实世界中的大规模不平衡数据集，其2018年版本共有437513个训练图像，共8142个类。训练数据集具有长尾标签分布，验证集被设计成具有均衡的标签分布。我们使用ResNet-50作为inaturalist 2018所有实验的网络。表3总结了iNaturalist 2018的top-1和top-5验证错误率。
### 消融实验
- 评估在少数类上的泛化性能：图2:在阶跃不平衡的CIFAR-10上，每个类的top-1错误率。0-F到4-F是多数类
- 评估延迟再平衡方法：图3：长尾不平衡数据集CIFAR-10的不平衡的训练误差（虚线）和平衡的测试误差（实线）。在160次迭代的时候进行学习率退火，提出的DRW方法在学习率退火之前使用的是ERM算法，性能不如RW和RS，退火学习率后，要优于其他。

