# Abstract #
- Transformer 架构早已在自然语言处理任务中得到广泛应用，但在计算机视觉领域中仍然受到限制。在计算机视觉领域，注意力要么与卷积网络结合使用，要么用来代替卷积网络的某些组件，同时保持其整体架构不变。
- 该研究表明，对 CNN 的依赖不是必需的，当直接应用于图像块序列时，transformer 也能很好地执行图像分类任务。该研究基于大量数据进行模型预训练，并迁移至多个图像识别基准数据集（ImageNet、CIFAR-100、VTAB 等），结果表明 Vision Transformer（ViT）模型可以获得与当前最优卷积网络相媲美的结果，而其训练所需的计算资源大大减少。
# 1 Introduction #
- 受到 NLP 领域中 Transformer 缩放成功的启发，这项研究尝试将标准 Transformer 直接应用于图像，并尽可能减少修改。为此，该研究将图像分割成多个图像块（patch），并将这些图像块的线性嵌入序列作为 Transformer 的输入。然后用 NLP 领域中处理 token 的方式处理图像块，并以监督的方式训练图像分类模型。
- 在中等规模的数据集（如 ImageNet）上训练时，这样的模型产生的结果并不理想，准确率比同等大小的 ResNet 低几个百分点。这个看似令人沮丧的结果是可以预料的：Transformer 缺少一些 CNN 固有的归纳偏置，例如平移同变性和局部性，因此在数据量不足的情况下进行训练后，Transformer 不能很好地泛化
- 但是，如果在大型数据集（14M-300M 张图像）上训练模型，则情况大为不同。该研究发现大规模训练胜过归纳偏置。在足够大的数据规模上进行预训练并迁移到数据点较少的任务时，Transformer 可以获得出色的结果
- 该研究提出的 Vision Transformer 在 JFT-300M 数据集上进行预训练，在多个图像识别基准上接近或超过了 SOTA 水平，在 ImageNet 上达到了 88.36% 的准确率，在 ImageNet ReaL 上达到了 90.77% 的准确率，在 CIFAR-100 上达到了 94.55% 的准确率，在 VTAB 基准 19 个任务中达到了 77.16% 的准确率。
# 2 方法 # 
- 研究者尽可能地遵循原始 Transformer 的设计。这种故意为之的简单设置具有以下优势，即可扩展 NLP Transformer 架构和相应的高效实现几乎可以实现开箱即用。研究者想要证明，当进行适当地扩展时，该方法足以超越当前最优的卷积神经网络。
## 3.1 Vision Transformer（ViT）##
- 图 1 为模型架构图 我们将图像分割成固定大小的块，线性地嵌入每个块，添加位置嵌入，并将得到的向量序列输入标准的转换器编码器。为了进行分类，我们使用标准的方法在序列中添加额外可学习的“分类标记”。
- 标准 Transformer 接收 1D 序列的 token 嵌入为输入。为了处理 2D 图像，研究者将图像 x ∈ R^H×W×C 变形为一系列的扁平化 2D patch x_p ∈ R^N×(P^2 ·C)，其中 (H, W) 表示原始图像的分辨率，(P, P) 表示每个图像 patch 的分辨率。然后，N = HW/P^2 成为 Vision Transformer 的有效序列长度。Vision Transformer 在所有层使用相同的宽度，将每个flatten的patch 映射到可训练的线性投影的D维上（公式 1），相应的输出被称为 patch 嵌入
- 与 BERT 的 [class] token 类似，研究者在一系列嵌入 patch （z_0^0 = x_class）之前预先添加了一个可学习嵌入，它在 Transformer 编码器（z_0^L ）输出中的状态可以作为图像表示 y（公式 4）。在预训练和微调阶段，分类头（head）依附于 z_L^0
- 位置嵌入被添加到 patch 嵌入中以保留位置信息。研究者尝试了位置嵌入的不同 2D 感知变体，但与标准 1D 位置嵌入相比并没有显著的增益。所以，编码器以联合嵌入为输入。
- Transformer 编码器由多个交互层的多头自注意力（MSA）和 MLP 块组成（公式 2、3）。每个块之前应用 Layernorm（LN），而残差连接在每个块之后应用。MLP 包含两个呈现 GELU 非线性的层。
- （1）每个flatten的patch 映射到可训练的线性投影的D维
- （2）MSA
- （3）MLP
- （4）Transformer 编码器（z_0^L ）输出中的状态可以作为图像表示 y
- 感应偏压。我们注意到，视觉变压器比CNN具有更少的图像特异性感应偏差。在CNNs中，局部性、二维邻域结构和翻译等变项被烘焙到整个模型的每一层。在ViT中，只有MLP层是局部的和易变的，而自我注意层是全局的。二维邻域结构的使用非常少：在模型开始时，通过将图像分割成小块，并在微调时间调整不同分辨率图像的位置嵌入（如下所述）。除此之外，初始化时的位置嵌入不包含关于补片的2D位置的信息，并且必须从头开始学习补片之间的所有空间关系
